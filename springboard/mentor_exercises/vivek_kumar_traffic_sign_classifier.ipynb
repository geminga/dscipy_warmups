{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic sign classifier neural network\n",
    "```Trunk code by Vivek Kumar, commentary and attempts to develop the LeCun et al. solution by M.L.```\n",
    "\n",
    "### Goals of this exercise\n",
    "* Reproduce LeCun & team classification results using Python ML-libraries\n",
    "* Improve if possible by trying the following\n",
    "    * Standardize luminosity and colours (LeCun et al. ended up dropping colours, which I see as a fail, human perceptual system normalizes light and colour hues, how about trying the same and retaining colour as a classifying input? It is pretty solid classifier - it seems frankly stupid to let the neural network be misguided due to seeing a yellow in the dark as different colour than yellow in the light? I think we could attempt to standardize colours so that the machine sees \"a yellow\" and \"a red\" etc. and try what kind of predictions we end up with.)\n",
    "    * ...would the above be achieved by a colour classifying SOM -layer (https://www.slideshare.net/raphaelkiminya/kohonen-self-organizing-maps)\n",
    "    * adding jitter was also suggested\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\andro\\\\repositories\\\\dscipy_warmups\\\\springboard\\\\mentor_exercises'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.16.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need this for handling serialized binary objects \n",
    "# (which the pics are apparently)\n",
    "# Check out joblib as well\n",
    "import pickle\n",
    "\n",
    "# OK, but which sets are the ones you used and on what basis did you select?\n",
    "# there was quite a plethora of different datasets on offer\n",
    "# haar, hog, gt, hue-hist? Wut?\n",
    "# Did you do pre-processing other than what is seen here, the \"multilabel binarizer\"? What does it do?\n",
    "# If yes, what exactly?\n",
    "     # 100K  GTSRB_Final_Test_GT.zip\n",
    "     # 305M  GTSRB_Final_Test_Haar.zip\n",
    "     # 279M  GTSRB_Final_Test_HOG.zip\n",
    "     # 4.6M  GTSRB_Final_Test_HueHist.zip\n",
    "     \n",
    "     # 945M  GTSRB_Final_Training_Haar.zip\n",
    "     # 864M  GTSRB_Final_Training_HOG.zip\n",
    "     #  18M  GTSRB_Final_Training_HueHist.zip\n",
    "     \n",
    "     #  85M  GTSRB_Final_Test_Images.zip\n",
    "     # 264M  GTSRB_Final_Training_Images.zip\n",
    "    # Vivek split some of the training data to the validation population\n",
    "\n",
    "# the source data from the German site does not match this one, so how did we get here?\n",
    "training_file   = 'C:\\\\Users\\\\andro\\\\repositories\\\\dscipy_warmups\\\\springboard\\\\mentor_exercises\\\\data\\\\traffic-signs-data\\\\train.p'\n",
    "validation_file = 'C:\\\\Users\\\\andro\\\\repositories\\\\dscipy_warmups\\\\springboard\\\\mentor_exercises\\\\data\\\\traffic-signs-data\\\\valid.p'\n",
    "testing_file    = 'C:\\\\Users\\\\andro\\\\repositories\\\\dscipy_warmups\\\\springboard\\\\mentor_exercises\\\\data\\\\traffic-signs-data\\\\test.p'\n",
    "\n",
    "# loading in the image populations\n",
    "# ..have you had binary file corruption on Windows with this \"read binary\" -mode\n",
    "# try without b-option first\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "\n",
    "# I need to check the schema/shape of the pickle\n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41 41 41 ... 25 25 25]\n"
     ]
    }
   ],
   "source": [
    "print(train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['coords', 'labels', 'features', 'sizes'])\n"
     ]
    }
   ],
   "source": [
    "print(train.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 34799\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32, 3)\n",
      "Number of classes = 43\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# population samples to vars with len\n",
    "n_train = len(X_train)\n",
    "n_validation = len(X_valid)\n",
    "n_test = len(X_test)\n",
    "\n",
    "image_shape = X_train.shape[1:] # all of the second column\n",
    "\n",
    "# just appending the populations\n",
    "classes = np.append(y_train, y_valid)\n",
    "classes = np.append(classes, y_test)\n",
    "n_classes = len(set(classes))\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print histograms of training and testing distributions with 43 bins\n",
    "# 43 is the number of actual labels, hence the bins.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplots(sharex=True, nrows=3, ncols=1, figsize=(15,8) ) # sharex does nothing :(\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "hist, bins = np.histogram(y_train, bins=43)\n",
    "width = 0.7 * (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "plt.bar(center, hist, align='center', width=width)\n",
    "plt.title('Training set')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "hist, bins = np.histogram(y_valid, bins=43)\n",
    "width = 0.7 * (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "plt.bar(center, hist, align='center', width=width)\n",
    "plt.title('Validation set')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "hist, bins = np.histogram(y_test, bins=43)\n",
    "width = 0.7 * (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "plt.bar(center, hist, align='center', width=width)\n",
    "plt.title('Testing set')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB channels handling here - to greyscale\n",
    "# but where is the actual image information - that is pixel greyscale values?\n",
    "# 1) (here I would be doing a split after first trying it like this)\n",
    "# 2) try it with colour as is\n",
    "# 3) try it with colour averaging, which should cancel out the lighting conditions complained about by original authors\n",
    "X_train = np.sum(X_train/3, axis=3, keepdims=True)\n",
    "X_valid = np.sum(X_valid/3, axis=3, keepdims=True)\n",
    "X_test = np.sum(X_test/3, axis=3, keepdims=True)\n",
    "\n",
    "X_train = (X_train - 128)/128\n",
    "X_valid = (X_valid - 128)/128\n",
    "X_test = (X_test - 128)/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bunch of different CNN layer types here: convolution, max-pooling\n",
    "# Rectified linear units (relu) chosen to enhance non-linear properties of network \n",
    "# (but isn't this a layer type in itself, it is in \"activation\")\n",
    "# 2 kinds of layers - function layers, weight layers\n",
    "\n",
    "# What do strides do in NN usage?\n",
    "# input_shape 32,32,1 ...32 px * 32 px and..1?\n",
    "\n",
    "# I installed the CPU -version...what about the GPU -version?\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "# Flatten: a vector from a matrix: input, tensor of 3 dimensions (height width channels) - output will be vector\n",
    "# Dense: vector to vectors \n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Concatenate\n",
    "\n",
    "from keras.layers.convolutional import AtrousConvolution2D\n",
    "from keras import backend as K # when doing stuff not in Keras, new layer, new callback -> allows extending Keras\n",
    "\n",
    "\n",
    "def model_traffic_sign(input_tensor=None):\n",
    "    input_shape = (32, 32, 1) # for colour images, use all channels\n",
    "\n",
    "    img_input = Input(shape=input_shape)\n",
    "    \n",
    "# how does this layering work - you just re-assign x...and then build another layer, \n",
    "# at the end of which you kinda concatenate the previous layer?\n",
    "# Which documentation part should I read here? - keras.layers -api? - Convolution2D and MaxPooling2D apis\n",
    "\n",
    "\n",
    "    # conv_1\n",
    "    x = Convolution2D(6, (5, 5), activation='relu', padding='valid', name='block1_conv1')(img_input)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # conv_2\n",
    "    x = Convolution2D(16, (5, 5), activation='relu', padding='valid', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "    \n",
    "    layer2 = x\n",
    "    \n",
    "    x = Convolution2D(400, (5, 5), activation='relu', padding='valid', name='block2_conv1')(x)\n",
    "    #x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    layer2_flat = Flatten()(layer2)\n",
    "    \n",
    "    x = Concatenate()([x, layer2_flat])\n",
    "    #x = Dense(120, activation=\"relu\")(x)\n",
    "    x = Dense(43, activation=\"softmax\")(x)\n",
    "\n",
    "    \n",
    "    model = Model(img_input, x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\andro\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 28, 28, 6)    156         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 14, 14, 6)    0           block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 10, 10, 16)   2416        block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 5, 5, 16)     0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 1, 1, 400)    160400      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 400)          0           block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 400)          0           block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 800)          0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 43)           34443       concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 197,415\n",
      "Trainable params: 197,415\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# stochastic gradient descent optimization algo variant\n",
    "from keras.optimizers import Adam \n",
    "\n",
    "model = model_traffic_sign()\n",
    "optim = Adam(lr = 0.0009)   # what is this magic number and where is it from? \n",
    "                            # ..lowest learning rate you can practically use less than 0.001\n",
    "model.compile(optim, loss='categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras utils in general has lots of nice stuff, read.\n",
    "# \n",
    "from tensorflow.keras.utils import Sequence \n",
    "class MySequence(Sequence):\n",
    "\n",
    "        def __init__(self, x_set, y_set, batch_size):\n",
    "            self.x, self.y = x_set, y_set\n",
    "            self.batch_size = batch_size\n",
    "\n",
    "        def __len__(self):\n",
    "            return math.ceil(len(self.x) / self.batch_size)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            batch_x = self.x[idx * self.batch_size:(idx + 1) *\n",
    "            self.batch_size]\n",
    "            batch_y = self.y[idx * self.batch_size:(idx + 1) *\n",
    "            self.batch_size]\n",
    "\n",
    "            return batch_x,  batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying the Raw labels to a form which can be used by our model \n",
    "from sklearn.preprocessing import MultiLabelBinarizer # again read docs but basically one-hot coding of labels\n",
    "\n",
    "classes = classes.reshape(len(classes),1)\n",
    "lbl_enc = MultiLabelBinarizer()\n",
    "lbl_enc.fit(classes)\n",
    "lbs_train = lbl_enc.transform(y_train.reshape(len(y_train), 1))\n",
    "lbs_valid = lbl_enc.transform(y_valid.reshape(len(y_valid), 1))\n",
    "lbs_test = lbl_enc.transform(y_test.reshape(len(y_test), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.00893784686923027\n",
      "epoch no-> 0 val_acc-> 0.9260770975056689\n",
      "loss: 0.010782591998577118\n",
      "epoch no-> 1 val_acc-> 0.9222222222222223\n",
      "loss: 0.007235602010041475\n",
      "epoch no-> 2 val_acc-> 0.9210884353741496\n",
      "loss: 0.007475446909666061\n",
      "epoch no-> 3 val_acc-> 0.9238095238095239\n",
      "loss: 0.008697006851434708\n",
      "epoch no-> 4 val_acc-> 0.9006802721088435\n",
      "loss: 0.021122440695762634\n",
      "epoch no-> 5 val_acc-> 0.9240362811791383\n",
      "loss: 0.008197229355573654\n",
      "epoch no-> 6 val_acc-> 0.9294784580498866\n",
      "loss: 0.014335260726511478\n",
      "epoch no-> 7 val_acc-> 0.9365079365079365\n",
      "loss: 0.06757121533155441\n",
      "epoch no-> 8 val_acc-> 0.9340136054421768\n",
      "loss: 0.0011150178033858538\n",
      "epoch no-> 9 val_acc-> 0.9328798185941043\n",
      "loss: 0.004076881799846888\n",
      "epoch no-> 10 val_acc-> 0.9356009070294785\n",
      "loss: 0.0035826596431434155\n",
      "epoch no-> 11 val_acc-> 0.9317460317460318\n",
      "loss: 0.010618667118251324\n",
      "epoch no-> 12 val_acc-> 0.9303854875283447\n",
      "loss: 0.004813934676349163\n",
      "epoch no-> 13 val_acc-> 0.9111111111111111\n",
      "loss: 0.009564138017594814\n",
      "epoch no-> 14 val_acc-> 0.9276643990929705\n",
      "loss: 0.008582078851759434\n",
      "epoch no-> 15 val_acc-> 0.9301587301587302\n",
      "loss: 0.004598342813551426\n",
      "epoch no-> 16 val_acc-> 0.9346938775510204\n",
      "loss: 0.00037269771564751863\n",
      "epoch no-> 17 val_acc-> 0.935374149659864\n",
      "loss: 0.0009289792506024241\n",
      "epoch no-> 18 val_acc-> 0.9392290249433106\n",
      "loss: 0.0636662095785141\n",
      "epoch no-> 19 val_acc-> 0.9340136054421768\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle # randomizing of training data\n",
    "\n",
    "n_epoches = 20\n",
    "batch_size = 256\n",
    "n_steps = int(n_train / batch_size)\n",
    "\n",
    "for i in range(n_epoches):\n",
    "    X_train, lbs_train = shuffle(X_train, lbs_train)\n",
    "    data_gen = MySequence(X_train, lbs_train, batch_size=batch_size)\n",
    "\n",
    "    for j in range(n_steps):\n",
    "        x, y = data_gen[j]\n",
    "        loss = model.train_on_batch(x, y)\n",
    "        \n",
    "    val_pred = model.predict(X_valid)\n",
    "    pred = np.argmax(val_pred, 1)\n",
    "    true = np.where(lbs_valid == 1)[1]\n",
    "    correct = sum(np.equal(true, pred))\n",
    "    val_acc = correct/len(X_valid)\n",
    "    print(\"loss: {}\".format(loss))\n",
    "    print(\"epoch no-> {} val_acc-> {}\".format(i, val_acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(X_test)\n",
    "pred = np.argmax(test_pred, 1)\n",
    "true = np.where(lbs_test == 1)[1]\n",
    "correct = sum(np.equal(true, pred))\n",
    "test_acc = correct/len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = model.predict(X_train)\n",
    "pred = np.argmax(train_pred, 1)\n",
    "true = np.where(lbs_train == 1)[1]\n",
    "correct = sum(np.equal(true, pred))\n",
    "train_acc = correct/len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next actions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - add precision_recall too - scikit learn for that so you get some indications of model accuracy \n",
    " - Classification report - use this\n",
    " - For each class each image - probability distributions per class\n",
    " - Confusion matrices for the predictions\n",
    " - Plot the images, make labels readable\n",
    " - check out misclassified images.\n",
    " - Enlarge the histograms so they are readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34799\n"
     ]
    }
   ],
   "source": [
    "print(len(pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34799, 43)\n"
     ]
    }
   ],
   "source": [
    "print(train_pred.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
